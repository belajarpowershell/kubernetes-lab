- name: apt-update on all Ubuntu nodes
  hosts: k3s_cluster
  become: yes
  tasks:
    - name: apt
      apt:
        update_cache: yes
        upgrade: 'yes'

## install kubectl on alpine1
- name: Update kubeconfig
  hosts: localhost
  gather_facts: false
  tasks:
    - name: Install curl
      become: yes
      apk:
        name: curl
        state: present
    - name: Install collection community.general
      community.general.ansible_galaxy_install:
        type: collection
        name: community.general
    - name: Update repositories and install kubectl package
      become: yes
      community.general.apk:
        name: kubectl
        update_cache: true
        repository: http://dl-cdn.alpinelinux.org/alpine/edge/community


- name: Install Docker on Loadbalancer Ubuntu
  hosts: lb
  become: true
  tasks:
  
    - name: Update package index
      apt:
        update_cache: yes

    - name: Install ca-certificates and curl
      apt:
        name: "{{ item }}"
        state: present
      loop:
        - ca-certificates
        - curl
        - apt-transport-https
        - software-properties-common

    - name: Import Docker APT repository GPG key
      apt_key:
        url: https://download.docker.com/linux/ubuntu/gpg
        state: present

    - name: Add Docker APT repository
      apt_repository:
        repo: "deb [arch=amd64] https://download.docker.com/linux/ubuntu focal stable"
        state: present
      register: apt_repo_result

    - name: Update package index (again)
      apt:
        update_cache: yes

    - name: Install Docker
      apt:
        name: 
          - docker-ce
          - docker-ce-cli
          - containerd.io
          - docker-buildx-plugin
          - docker-compose-plugin
        state: present

    - name: Create docker group
      group:
        name: docker
        state: present

    - name: Add current user to docker group
      user:
        name: "{{ ansible_user }}"
        groups: docker
        append: yes

    - name: Restart Docker service
      service:
        name: docker
        state: restarted

    - name: Enable Docker service at boot
      service:
        name: docker
        enabled: yes

    - name: Enable Containerd service at boot
      service:
        name: containerd
        enabled: yes

    - name: Create /etc/nginx.conf file
      template:
        src: /srv/ansible/playbook-k3s/j2/nginx.conf.j2
        dest: /etc/nginx.conf

    - name: Run Nginx Docker container
      docker_container:
        name: k3s-LB-nginx_container
        image: nginx:1.14
        detach: true
        restart_policy: unless-stopped
        ports:
          - "6443:6443"
          - "443:443"
          - "8080:8080"
        volumes:
          - "/etc/nginx.conf:/etc/nginx/nginx.conf"


  handlers:
    - name: Restart Docker
      systemd:
        name: docker
        state: restarted


- name: Prereq Disable Firewalld, SELinux, Multipath, and Swap
  hosts: master,masterHA,worker
  become: true

  tasks:
    - name: Disable Firewalld
      systemd:
        name: ufw
        enabled: no
        state: stopped

    - name: Disable Multipath
      systemd:
        name: multipathd
        enabled: no
        state: stopped

    - name: Disable Swap
      ansible.builtin.mount:
        path: swap
        state: absent
    - name: Create /var/log/kubernetes directory
      ansible.builtin.file:
        path: /var/log/kubernetes
        state: directory

    - name: Create /var/log/kubernetes/audit directory
      ansible.builtin.file:
        path: /var/log/kubernetes/audit
        state: directory

    - name: Create /var/lib/rancher directory
      ansible.builtin.file:
        path: /var/lib/rancher/
        state: directory

    - name: Create /var/lib/rancher/k3s directory
      ansible.builtin.file:
        path: /var/lib/rancher/k3s
        state: directory

    - name: Create /var/lib/rancher/k3s/server directory
      ansible.builtin.file:
        path: /var/lib/rancher/k3s/server
        state: directory

    - name: Create /var/lib/rancher/k3s/server/manifests directory
      ansible.builtin.file:
        path: /var/lib/rancher/k3s/server/manifests
        state: directory

    - name: Create audit.yaml file
      ansible.builtin.copy:
        content: |
          apiVersion: audit.k8s.io/v1 
          kind: Policy
          rules:
            - level: Metadata
        dest: /var/lib/rancher/k3s/server/manifests/audit.yaml


- name: Install K3S on master
  hosts: master
  become: true
  gather_facts: false

  vars_files:
    - /srv/ansible/playbook-k3s/ansible-vars.yml

  tasks:
    - name: Get Load Balancer Hostname from Inventory
      set_fact:
        load_balancer_hostname: "{{ hostvars[groups['lb'][0]].inventory_hostname }}"
    - name: Check if kubectl is installed
      command: "which kubectl"
      register: kubectl_installed
      ignore_errors: true

    - name: Check if k3s is installed
      command: "which k3s"
      register: k3s_installed
      ignore_errors: true

    - name: Echo kubectl Installation Status
      debug:
        var: kubectl_installed.rc

    - name: Echo k3s Installation Status
      debug:
        var: k3s_installed.rc

    - name: Echo loadbalance-hostname
      debug:
        var: load_balancer_hostname

    - name: Run K3S Installation Script master
      shell:  "{{ k3s_installation_script_master }}"
      register: k3s_installation_result
      changed_when: k3s_installation_result.stdout is not none
      when: kubectl_installed.rc != 0 or k3s_installed.rc != 0

    - name: Wait for node to be ready
      become: yes
      ansible.builtin.shell: $([[ $(kubectl get node $(cat /etc/hostname) -o jsonpath='{.status.conditions[?(@.type=="Ready")].status}') == "True" ]])
      args:
        executable: /bin/bash
      register: kubelet_ready
      until: kubelet_ready.rc == 0
      retries: 60
      delay: 3

    - name: Change file access node-token
      file:
        path: /var/lib/rancher/k3s/server
        mode: "g+rx,o+rx"
      run_once: yes
    - name: Read node-token from master
      slurp:
        src: /var/lib/rancher/k3s/server/node-token
      register: node_token
      run_once: yes

    - name: Store Master node-token
      set_fact:
        k3s_token: "{{ node_token.content | b64decode | regex_replace('\n', '') }}"
      run_once: yes
    - name: Echo Token Result master
      debug:
        var: k3s_token

- name: Install K3S on subsequent master nodes
  hosts: masterHA
  become: true
  gather_facts: false

  vars_files:
    - /srv/ansible/playbook-k3s/ansible-vars.yml

  tasks:
    - name: Get Load Balancer Hostname from Inventory
      set_fact:
        load_balancer_hostname: "{{ hostvars[groups['lb'][0]].inventory_hostname }}"

    - name: Check if kubectl is installed
      command: "which kubectl"
      register: kubectl_installed
      ignore_errors: true

    - name: Check if k3s is installed
      command: "which k3s"
      register: k3s_installed
      ignore_errors: true

    - name: Echo kubectl Installation Status
      debug:
        var: kubectl_installed.rc

    - name: Echo k3s Installation Status
      debug:
        var: k3s_installed.rc
    - name: Set Token Fact for masterHA
      set_fact:
        k3s_token: "{{ hostvars[groups['master'][0]].k3s_token }}"
    - name: Run K3S Installation Script MasterHA
      shell: "{{ k3s_installation_script_masterHA }}"
      register: k3s_installation_result
      changed_when: k3s_installation_result.stdout is not none
      when: kubectl_installed.rc != 0 or k3s_installed.rc != 0

    - name: Wait for node to be ready
      become: yes
      ansible.builtin.shell: $([[ $(kubectl get node $(cat /etc/hostname) -o jsonpath='{.status.conditions[?(@.type=="Ready")].status}') == "True" ]])
      args:
        executable: /bin/bash
      register: kubelet_ready
      until: kubelet_ready.rc == 0
      retries: 60
      delay: 3

- name: Install K3S agent  on worker nodes
  hosts: worker
  become: true
  gather_facts: false
  vars_files:
    - /srv/ansible/playbook-k3s/ansible-vars.yml

  tasks:
    - name: Get Load Balancer Hostname from Inventory
      set_fact:
        #load_balancer_hostname: "{{ hostvars['loadbalancer'].inventory_hostname }}"
        load_balancer_hostname: "{{ hostvars[groups['lb'][0]].inventory_hostname }}"
    - name: Set Token Fact for Workers
      set_fact:
        k3s_token: "{{ hostvars[groups['master'][0]].k3s_token }}"
    - name: Check if kubectl is installed
      command: "which kubectl"
      register: kubectl_installed
      ignore_errors: true

    - name: Check if k3s is installed
      command: "which k3s"
      register: k3s_installed
      ignore_errors: true

    - name: Echo kubectl Installation Status
      debug:
        var: kubectl_installed.rc

    - name: Echo k3s Installation Status
      debug:
        var: k3s_installed.rc

    - name: Run K3S Installation Script worker
      shell: "{{ k3s_installation_script_worker }}"
      register: k3s_installation_result
      changed_when: k3s_installation_result.stdout is not none
      when: kubectl_installed.rc != 0 or k3s_installed.rc != 0


- name: Copy kubeconfig from master1 to ansible server
  hosts: master1
  tasks:
    - name: Fetch kubeconfig
      fetch:
        src: "/etc/rancher/k3s/k3s.yaml"
        dest: "./ctx-{{ k3s_cluster_name }}.yaml"
        flat: yes

- name: Update kubeconfig
  hosts: localhost
  gather_facts: false
  tasks:
    - name: Get Load Balancer Hostname and Cluster Name
      set_fact:
        lb_hostname: "{{ groups['lb'][0] }}"
        #cluster_name: "{{ k3s_cluster_name }}"
        cluster_name: "{{ k3s_cluster_name }}"

    - name: Replace name and IP in kubeconfig
      replace:
        path: "./ctx-{{ k3s_cluster_name }}.yaml"
        regexp: "https://127.0.0.1:6443"
        replace: "https://{{ lb_hostname }}:6443"
      delegate_to: localhost

    - name: Read k3s.yaml
      slurp:
        path: "./ctx-{{ k3s_cluster_name }}.yaml"
      register: k3s_yaml_content

    - name: Update k3s.yaml with cluster name
      set_fact:
        k3s_yaml: "{{ k3s_yaml_content.content | b64decode | from_yaml }}"
     
    - name: update cluster info
      set_fact:
        k3s_yaml: "{{ k3s_yaml | default({'clusters': []}) | combine({'clusters': [{'name': cluster_name , 'cluster': {'certificate-authority-data': k3s_yaml.clusters[0].cluster['certificate-authority-data'], 'server': k3s_yaml.clusters[0].cluster['server']}}]}, recursive=True) }}"
   

    - name: update user info
      set_fact:
        k3s_yaml: "{{ k3s_yaml | combine({'users': [{'name': cluster_name + '-default-user', 'user': {'client-certificate-data': k3s_yaml.users[0].user['client-certificate-data'], 'client-key-data': k3s_yaml.users[0].user['client-key-data'] }}]}) }}"


    - name: Update contexts info
      set_fact:
        k3s_yaml: "{{ k3s_yaml | combine({'contexts': [{'context': {'cluster': cluster_name, 'user': cluster_name + '-default-user'}, 'name': 'ctx-' + cluster_name}]} ) }}"

    - name: Update current-context
      set_fact:
        k3s_yaml: "{{ k3s_yaml | combine({'current-context': 'ctx-' + cluster_name}) }}"


    - name: Write updated k3s.yaml
      copy:
        content: "{{ k3s_yaml | to_nice_yaml(indent=2) }}"
        dest: "./ctx-{{ cluster_name }}.yaml"
  
    - name: Ensure the directory exists /root/.kube/clusters/
      ansible.builtin.file:
        path: "/root/.kube/clusters/"
        state: directory
    
    - name: Write updated k3s.yaml /root/.kube/clusters/
      copy:
        content: "{{ k3s_yaml | to_nice_yaml(indent=2) }}"
        dest: "/root/.kube/clusters/ctx-{{ cluster_name }}.yaml"


- name: Prereq Disable Firewalld, SELinux, Multipath, and Swap 
  hosts: single
  become: true
  

  tasks:
    - name: Disable Swap
      ansible.builtin.mount:
        path: swap
        state: absent
    - name: Create /var/log/kubernetes directory
      ansible.builtin.file:
        path: /var/log/kubernetes
        state: directory

    - name: Create /var/log/kubernetes/audit directory
      ansible.builtin.file:
        path: /var/log/kubernetes/audit
        state: directory

    - name: Create /var/lib/rancher directory
      ansible.builtin.file:
        path: /var/lib/rancher/
        state: directory

    - name: Create /var/lib/rancher/k3s directory
      ansible.builtin.file:
        path: /var/lib/rancher/k3s
        state: directory

    - name: Create /var/lib/rancher/k3s/server directory
      ansible.builtin.file:
        path: /var/lib/rancher/k3s/server
        state: directory

    - name: Create /var/lib/rancher/k3s/server/manifests directory
      ansible.builtin.file:
        path: /var/lib/rancher/k3s/server/manifests
        state: directory

    - name: Create audit.yaml file
      ansible.builtin.copy:
        content: |
          apiVersion: audit.k8s.io/v1 
          kind: Policy
          rules:
            - level: Metadata
        dest: /var/lib/rancher/k3s/server/manifests/audit.yaml


- name: Install K3S on single
  hosts: single
  become: true
  gather_facts: false

  vars_files:
    - /srv/ansible/playbook-k3s/ansible-vars.yml

  tasks:
    - name: Get Load Balancer Hostname from Inventory ( singlenode hostname)
      set_fact:
        load_balancer_hostname: "{{ groups['single'][0] }}"
    - name: Check if kubectl is installed
      command: "which kubectl"
      register: kubectl_installed
      ignore_errors: true

    - name: Check if k3s is installed
      command: "which k3s"
      register: k3s_installed
      ignore_errors: true

    - name: Echo kubectl Installation Status
      debug:
        var: kubectl_installed.rc

    - name: Echo k3s Installation Status
      debug:
        var: k3s_installed.rc

    - name: Echo loadbalance-hostname
      debug:
        var: load_balancer_hostname

    - name: Run K3S Installation Script single
      shell:  "{{ k3s_installation_script_single }}"
      register: k3s_installation_result
      changed_when: k3s_installation_result.stdout is not none
      when: kubectl_installed.rc != 0 or k3s_installed.rc != 0


    - name: Wait for node to be ready
      become: yes
      ansible.builtin.shell: $([[ $(kubectl get node $(cat /etc/hostname) -o jsonpath='{.status.conditions[?(@.type=="Ready")].status}') == "True" ]])
      args:
        executable: /bin/bash
      register: kubelet_ready
      until: kubelet_ready.rc == 0
      retries: 60
      delay: 3


- name: Copy kubeconfig from singlenode to ansible server
  hosts: single
  tasks:
    - name: Echo generated hostname
      debug:
        var: groups['single'][0]

    - name: Fetch kubeconfig
      fetch:
        src: "/etc/rancher/k3s/k3s.yaml"
        dest: "./ctx-{{ k3s_single_name}}.yaml"
        flat: yes

- name: Update kubeconfig
  hosts: localhost
  gather_facts: false
  tasks:
    - name: Get Load Balancer Hostname and Cluster Name
      set_fact:
        single_hostname: "{{ groups['single'][0] }}"
        cluster_name: "{{ k3s_single_name}}"

    - name: Replace name and IP in kubeconfig
      replace:
        path: "./ctx-{{ cluster_name }}.yaml"
        regexp: "https://127.0.0.1:6443"
        replace: "https://{{ groups['single'][0] }}:6443"
      delegate_to: localhost

    - name: Read k3s.yaml
      slurp:
        path: "./ctx-{{ cluster_name }}.yaml"
      register: k3s_yaml_content

    - name: Update k3s.yaml with cluster name
      set_fact:
        k3s_yaml: "{{ k3s_yaml_content.content | b64decode | from_yaml }}"
     
    - name: update cluster info
      set_fact:
        k3s_yaml: "{{ k3s_yaml | default({'clusters': []}) | combine({'clusters': [{'name':cluster_name , 'cluster': {'certificate-authority-data': k3s_yaml.clusters[0].cluster['certificate-authority-data'], 'server': k3s_yaml.clusters[0].cluster['server']}}]}, recursive=True) }}"
   

    - name: update user info
      set_fact:
        k3s_yaml: "{{ k3s_yaml | combine({'users': [{'name': cluster_name + '-default-user', 'user': {'client-certificate-data': k3s_yaml.users[0].user['client-certificate-data'], 'client-key-data': k3s_yaml.users[0].user['client-key-data'] }}]}) }}"


    - name: Update contexts info
      set_fact:
        k3s_yaml: "{{ k3s_yaml | combine({'contexts': [{'context': {'cluster': cluster_name, 'user': cluster_name  + '-default-user'}, 'name': 'ctx-' + cluster_name}]} ) }}"

    - name: Update current-context
      set_fact:
        k3s_yaml: "{{ k3s_yaml | combine({'current-context': 'ctx-' + cluster_name }) }}"


    - name: Ensure the directory exists /root/.kube/clusters/
      ansible.builtin.file:
        path: "/root/.kube/clusters/"
        state: directory

    - name: Ensure the directory exists /root/.kube/clusters/
      ansible.builtin.file:
        path: "/root/.kube/clusters/"
        state: directory
    - name: Write updated k3s.yaml
      copy:
        content: "{{ k3s_yaml | to_nice_yaml(indent=2) }}"
        dest: "/root/.kube/clusters/ctx-{{ cluster_name }}.yaml"


- name: Generate kubeconfig file
  hosts: localhost
  gather_facts: false
  tasks:
    - name: Ensure script is executable
      become: true
      file:
        path: ~/kubernetes-lab/srv/ansible/playbook-k3s/generate_kubeconfig.sh  # Update with the correct path
        mode: "+x"

    - name: Run generate_kubeconfig.sh script
      become: true
      script: ~/kubernetes-lab/srv/ansible/playbook-k3s/generate_kubeconfig.sh  # Update with the correct path
